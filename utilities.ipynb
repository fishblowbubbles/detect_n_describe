{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenImagesV4 Data Preparation Utility For YOLOV3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module extracts images from the Open Images Dataset V4 that contain selected classes, generating a corresponding .txt or .xml file for each image as per the YOLO and PASCAL VOC annotation formats respectively and the necessary metadata files.\n",
    "\n",
    "You will need these libraries:\n",
    "    1. pandas\n",
    "    2. pascal_voc_writer\n",
    "    3. pillow\n",
    "    4. seaborn\n",
    "    5. tqdm\n",
    "    \n",
    "You require the following meta files, located in a single directory:\n",
    "    1. class_descriptions.csv\n",
    "    2. train_annotations.csv\n",
    "    3. train_images.csv\n",
    "    4. valid_annotations.csv\n",
    "    5. valid_images.csv\n",
    "    \n",
    "Subsequently, specify the source and destination paths accordingly, in the dictionaries:\n",
    "    1. src\n",
    "    2. dst\n",
    "\n",
    "Finally, indicate the output annotation format, as either:\n",
    "    1. \"YOLO\" or \n",
    "    2. \"PASCALVOC\"\n",
    "\n",
    "Your selected classes are stored as a list of class descriptions (case-sensitive) - add to or remove from it as needed.\n",
    "\n",
    "Optionally, you can limit the number of training and validation images copied by setting:\n",
    "    1. limit\n",
    "    2. n\n",
    "    \n",
    "Both training and validation images will be copied into a folder named 'custom', and the generated metadata files are:\n",
    "    1. custom.names - contains class descriptions\n",
    "    2. train.txt    - contains relative paths from darknet.exe to every trainin image\n",
    "    3. valid.txt    - contains relative paths from darknet.exe to every validation image\n",
    "    \n",
    "    i.e. data/custom/XXX.jpg\n",
    "    \n",
    "Your directory tree should look like this:\n",
    "\n",
    "```\n",
    "+-- darknet\n",
    "|   +-- data\n",
    "|   |   +-- custom\n",
    "|   |   |   +-- XXX.jpg\n",
    "|   |   |   +-- XXX.txt\n",
    "|   |   |   +-- YYY.jpg\n",
    "|   |   |   +-- YYY.txt\n",
    "|   |   |   ...\n",
    "|   |   +-- custom.names\n",
    "|   |   +-- train.txt\n",
    "|   |   +-- validation.txt\n",
    "|   ...\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pascal_voc_writer import Writer\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from shutil import copyfile\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aws', 's3', '--no-sign-request', 'cp', 's3://open-images-dataset/train/0908260ac3dccd9b.jpg', 'data/custom']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Completed 250.5 KiB/250.5 KiB (15.5 KiB/s) with 1 file(s) remaining\\ndownload: s3://open-images-dataset/train/0908260ac3dccd9b.jpg to data\\\\custom\\\\0908260ac3dccd9b.jpg\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = [\n",
    "    # \"Person\",\n",
    "    # \"Human face\",\n",
    "    # \"Hat\",\n",
    "    # \"Sunglasses\",\n",
    "    \"Knife\",\n",
    "    # \"Handgun\",\n",
    "    # \"Rifle\",\n",
    "    # \"Weapon\",\n",
    "    # \"Jacket\",\n",
    "    # \"Shorts\",\n",
    "    # \"Jeans\",\n",
    "    # \"Skirt\",\n",
    "]\n",
    "\n",
    "src = {\"train\": \"/media/tingyu/WD BLUE/open_images/all/train_0\", \n",
    "       \"valid\": \"/media/tingyu/WD BLUE/open_images/all/validation\", \n",
    "       \"meta\": \"data/meta\"}\n",
    "dst = \"data\"\n",
    "\n",
    "ann_format = \"PASCALVOC\"\n",
    "\n",
    "limit = {\"train\": False, \n",
    "         \"valid\": False}\n",
    "n = {\"train\": 0, \n",
    "     \"valid\": 0}\n",
    "\n",
    "s3 = \"aws s3 --no-sign-request cp s3://open-images-dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpenImagesUtility():\n",
    "    def __init__(self, classes, src, dst, ann_format, limit, n):\n",
    "        self.src = src\n",
    "        self.dst = dst\n",
    "        self.ann_format = ann_format\n",
    "        self.limit = limit\n",
    "        self.n = n\n",
    "        \n",
    "        self.class_desc = pd.read_csv(\"{}/class_descriptions.csv\".format(self.src[\"meta\"]), header=None)\n",
    "        self.class_desc.columns = [\"LabelName\", \"Description\"]\n",
    "        label_names = [self.class_desc[self.class_desc[\"Description\"] == c][\"LabelName\"].values[0]\n",
    "                       for c in classes]\n",
    "        \"\"\"\n",
    "        select LabelName, Description\n",
    "        from   class_desc\n",
    "        where  LabelName in label_names\n",
    "        \"\"\"\n",
    "        self.class_desc = (self.class_desc[self.class_desc[\"LabelName\"].isin(label_names)][[\"LabelName\", \"Description\"]]\n",
    "                           .sort_values([\"Description\"]))\n",
    "        self.class_desc = self.class_desc.reset_index(drop=True)\n",
    "        print(\"Total Classes: {}\".format(self.class_desc.shape[0]))\n",
    "        \n",
    "        train_anns = pd.read_csv(\"{}/train_annotations.csv\".format(self.src[\"meta\"]))\n",
    "        \"\"\"\n",
    "        select *\n",
    "        from   train_anns join class_desc\n",
    "               on LabelName\n",
    "        \"\"\"\n",
    "        train_anns = (pd.merge(train_anns, self.class_desc, on=\"LabelName\")\n",
    "                      .sort_values([\"ImageID\"]))\n",
    "        print(\"Total Training Annotations: {}\".format(train_anns.shape[0]))\n",
    "\n",
    "        train_imgs = pd.read_csv(\"{}/train_images.csv\".format(self.src[\"meta\"]))\n",
    "        \"\"\"\n",
    "        select *\n",
    "        from   train_imgs join (select distinct ImageID from train_anns) \n",
    "               on ImageID\n",
    "        \"\"\"\n",
    "        train_imgs = (pd.merge(train_imgs, pd.DataFrame(train_anns[\"ImageID\"].unique(), columns=[\"ImageID\"]), on=\"ImageID\")\n",
    "                      .sort_values([\"ImageID\"]))\n",
    "        print(\"Total Training Images: {}\".format(train_imgs.shape[0]))\n",
    "        \n",
    "        valid_anns = pd.read_csv(\"{}/valid_annotations.csv\".format(self.src[\"meta\"]))\n",
    "        \"\"\"\n",
    "        select *\n",
    "        from   valid_anns join class_desc\n",
    "               on LabelName\n",
    "        \"\"\"\n",
    "        valid_anns = (pd.merge(valid_anns, self.class_desc, on=\"LabelName\")\n",
    "                      .sort_values([\"ImageID\"]))\n",
    "        print(\"Total Validation Annotations: {}\".format(valid_anns.shape[0]))\n",
    "        \n",
    "        valid_imgs = pd.read_csv(\"{}/valid_images.csv\".format(self.src[\"meta\"]))\n",
    "        valid_imgs[\"ImageID\"] = valid_imgs[\"ImageID\"].apply(lambda s: s[0:len(s) - 4])\n",
    "        \"\"\"\n",
    "        select *\n",
    "        from   valid_imgs join (select distinct ImageID from valid_anns) \n",
    "               on ImageID\n",
    "        \"\"\"\n",
    "        valid_imgs = (pd.merge(valid_imgs, pd.DataFrame(valid_anns[\"ImageID\"].unique(), columns=[\"ImageID\"]), on=\"ImageID\")\n",
    "                      .sort_values([\"ImageID\"]))\n",
    "        print(\"Total Validation Images: {}\".format(valid_imgs.shape[0]))\n",
    "        \n",
    "        self.anns = {\"train\": train_anns, \n",
    "                     \"valid\": valid_anns}\n",
    "        self.imgs = {\"train\": train_imgs, \n",
    "                     \"valid\": valid_imgs}\n",
    "        \n",
    "    def _to_yolo_format(self, label_name, x_min, x_max, y_min, y_max):\n",
    "        \"\"\"\n",
    "        Converts annotations from PASCALVOC to YOLO format.\n",
    "        \"\"\"\n",
    "        label_idx = self.get_label_idx(label_name)\n",
    "        x_mid = (x_min + x_max) / 2\n",
    "        y_mid = (y_min + y_max) / 2\n",
    "        width = x_max - x_min\n",
    "        height = y_max - y_min\n",
    "        return \"{} {} {} {} {}\".format(label_idx, x_mid, y_mid, width, height)\n",
    "\n",
    "    def _mk_anns_txt(self, anns, folder_path, img_id):\n",
    "        \"\"\"\n",
    "        Create annotations .txt file in YOLO format.\n",
    "        \"\"\"\n",
    "        with open(\"{}/{}.txt\".format(folder_path, img_id), \"w+\") as file:    \n",
    "            file.write(\"\\n\".join([self._to_yolo_format(r[\"LabelName\"], r[\"XMin\"], r[\"XMax\"], r[\"YMin\"], r[\"YMax\"]) \n",
    "                                  for _, r in anns.iterrows()]))\n",
    "            file.close()\n",
    "\n",
    "    def _mk_anns_xml(self, anns, folder_path, img_id):\n",
    "        \"\"\"\n",
    "        Create annotations .xml file in PASCALVOC format.\n",
    "        \"\"\"\n",
    "        img = Image.open(\"{}/{}.jpg\".format(folder_path, img_id))\n",
    "        width, height = img.size\n",
    "        writer = Writer(folder_path, width, height)\n",
    "        for _, r in anns.iterrows():\n",
    "            label_desc = self.get_label_desc(r[\"LabelName\"])\n",
    "            x_min = round(r[\"XMin\"] * width)\n",
    "            x_max = round(r[\"XMax\"] * width)\n",
    "            y_min = round(r[\"YMin\"] * height)\n",
    "            y_max = round(r[\"YMax\"] * height)\n",
    "            writer.addObject(label_desc, x_min, y_min, x_max, y_max)\n",
    "        writer.save(\"{}/{}.xml\".format(folder_path, img_id))\n",
    "\n",
    "    def _mk_anns_file(self, anns, folder_path, img_id):\n",
    "        \"\"\"\n",
    "        Create annotations file in specified format.\n",
    "        \"\"\"\n",
    "        if self.ann_format == \"YOLO\":\n",
    "            self._mk_anns_txt(anns, folder_path, img_id)\n",
    "        elif self.ann_format == \"PASCALVOC\":\n",
    "            self._mk_anns_xml(anns, folder_path, img_id)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid annotation format\")\n",
    "    \n",
    "    def _cp_with_anns(self, imgs, anns, mode, limit, n):\n",
    "        \"\"\"\n",
    "        Copy image from source to destination and create corresponding annotations file in destination directory.\n",
    "        \n",
    "        Input(s):\n",
    "        1. imgs (dataframe) - ImageIDs to copy\n",
    "        2. anns (dataframe) - annotations for ImageIDs in imgs\n",
    "        3. src (str) - source folder path\n",
    "        4. limit (boolean) - copy n images if true, all otherwise\n",
    "        5. n (int) - no. of images to copy, relevant when limit=True\n",
    "        \n",
    "        Output(s):\n",
    "        1. paths (list) - paths to each copied image\n",
    "        2. logs (list) - caught error messages\n",
    "        \"\"\"\n",
    "        if not limit: \n",
    "            n = imgs.shape[0] \n",
    "        paths = []\n",
    "        logs = []\n",
    "        with tqdm(total=n) as pbar:\n",
    "            for _, r in imgs.iterrows():\n",
    "                if limit and len(paths) == n: \n",
    "                    break\n",
    "                try:\n",
    "                    cmd = \"{}/{}/{}.jpg custom\".format(s3, mode, r[\"ImageID\"])\n",
    "                    cmd = subprocess.run(cmd.split(), check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True)\n",
    "                    # copyfile(\"{}/{}.jpg\".format(src, r[\"ImageID\"]), \n",
    "                    #          \"{}/custom/{}.jpg\".format(self.dst, r[\"ImageID\"]))\n",
    "                    self._mk_anns_file(anns[anns[\"ImageID\"] == r[\"ImageID\"]],\n",
    "                                            \"{}/custom\".format(self.dst), \n",
    "                                            r[\"ImageID\"])\n",
    "                    paths.append(\"data/custom/{}.jpg\".format(r[\"ImageID\"]))\n",
    "                except FileNotFoundError:\n",
    "                    logs.append(\"{}.jpg not found\".format(r[\"ImageID\"]))\n",
    "                pbar.update()\n",
    "        return paths, logs\n",
    "    \n",
    "    def get_label_desc(self, label_name):\n",
    "        return self.class_desc[self.class_desc[\"LabelName\"] == label_name][\"Description\"].values[0]\n",
    "\n",
    "    def get_label_idx(self, label_name):\n",
    "        return self.class_desc[self.class_desc[\"LabelName\"] == label_name].index[0]\n",
    "    \n",
    "    def plt_anns_dist(self, mode):\n",
    "        \"\"\"\n",
    "        Displays a horizontal bar graph of the number of annotations per selected class.\n",
    "        \n",
    "        Input(s):\n",
    "        1. mode (str) - either \"train\" or \"valid\" \n",
    "        \"\"\"\n",
    "        dist = (self.anns[mode]\n",
    "                .groupby([\"LabelName\"])\n",
    "                .size()\n",
    "                .reset_index(name=\"Count\")\n",
    "                .sort_values([\"Count\"]))\n",
    "        dist[\"LabelName\"] = dist[\"LabelName\"].apply(self.get_label_desc)\n",
    "        plt.barh(y=dist[\"LabelName\"], width=dist[\"Count\"])\n",
    "        plt.show()\n",
    "        \n",
    "    def mk_dst_dirs(self):\n",
    "        \"\"\"\n",
    "        Create destination directories if not exists.\n",
    "        \"\"\"\n",
    "        if not os.path.exists(self.dst): os.mkdir(self.dst)\n",
    "        if not os.path.exists(\"{}/custom\".format(self.dst)):\n",
    "            os.mkdir(\"{}/custom\".format(self.dst))\n",
    "            \n",
    "    def mk_yolo_metas(self):\n",
    "        \"\"\"\n",
    "        Create necessary YOLO metadata files:\n",
    "        1. .names - contains all class descriptions, 1 per line\n",
    "        2. .data  - ?\n",
    "        \"\"\"\n",
    "        with open(\"{}/custom.names\".format(self.dst), \"w+\") as file:\n",
    "            file.write(\"\\n\".join(self.class_desc[\"Description\"].tolist()))\n",
    "            file.close()\n",
    "        with open(\"{}/custom.data\".format(self.dst), \"w+\") as file:\n",
    "            file.write(\"classes={}\" \\\n",
    "                       \"\\ntrain=data/train.txt\" \\\n",
    "                       \"\\nvalid=data/valid.txt\" \\\n",
    "                       \"\\nnames=data/custom.names\" \\\n",
    "                       \"\\nbackup=backup\"\n",
    "                       .format(self.class_desc.shape[0]))\n",
    "            file.close()\n",
    "        \n",
    "    def prep(self, mode):\n",
    "        paths, logs = self._cp_with_anns(self.imgs[mode], \n",
    "                                         self.anns[mode], \n",
    "                                         mode, \n",
    "                                         self.limit[mode], \n",
    "                                         self.n[mode])\n",
    "        with open(\"{}/{}.txt\".format(self.dst, mode), \"w+\") as txt:\n",
    "            txt.write(\"\\n\".join(paths))\n",
    "            txt.close()\n",
    "        return logs\n",
    "        \n",
    "    def start(self):\n",
    "        self.mk_dst_dirs()\n",
    "        self.mk_yolo_metas()\n",
    "        self.prep(\"train\")\n",
    "        self.prep(\"valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Classes: 1\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-83028d28c716>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mutility\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOpenImagesUtility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mann_format\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-fe92ca230e94>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, classes, src, dst, ann_format, limit, n)\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Total Classes: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_desc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mtrain_anns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{}/train_annotations.csv\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"meta\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \"\"\"\n\u001b[0;32m     25\u001b[0m         \u001b[0mselect\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tingyu\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tingyu\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 446\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    447\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m         \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tingyu\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1034\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'skipfooter not supported for iteration'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1035\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1036\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1037\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m         \u001b[1;31m# May alter columns / col_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tingyu\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1846\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1847\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1849\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers._try_int64\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "utility = OpenImagesUtility(classes, src, dst, ann_format, limit, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utility.plt_anns_dist(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utility.plt_anns_dist(\"valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 4457/10000 [14:33<16:02,  5.76it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-a0eb9f3ab80a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mutility\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-28-dcf1e64fed3c>\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmk_dst_dirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmk_yolo_metas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"valid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-dcf1e64fed3c>\u001b[0m in \u001b[0;36mprep\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    198\u001b[0m                                          \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m                                          \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m                                          self.n[mode])\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{}/{}.txt\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w+\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtxt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0mtxt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-dcf1e64fed3c>\u001b[0m in \u001b[0;36m_cp_with_anns\u001b[0;34m(self, imgs, anns, src, limit, n)\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                     copyfile(\"{}/{}.jpg\".format(src, r[\"ImageID\"]), \n\u001b[0;32m--> 141\u001b[0;31m                              \"{}/custom/{}.jpg\".format(self.dst, r[\"ImageID\"]))\n\u001b[0m\u001b[1;32m    142\u001b[0m                     self._mk_anns_file(anns[anns[\"ImageID\"] == r[\"ImageID\"]],\n\u001b[1;32m    143\u001b[0m                                             \u001b[0;34m\"{}/custom\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m                 \u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfsrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/shutil.py\u001b[0m in \u001b[0;36mcopyfileobj\u001b[0;34m(fsrc, fdst, length)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;34m\"\"\"copy data from file-like object fsrc to file-like object fdst\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "utility.start()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
