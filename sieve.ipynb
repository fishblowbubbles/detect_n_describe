{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INSTRUCTIONS\n",
    "\n",
    "This module extracts images from the Open Images Dataset V4 that contain selected classes and generates a corresponding .txt or .xml file for each image as per the YOLO and PASCAL VOC formats respectively.\n",
    "\n",
    "You will need these packages:\n",
    "    1. pandas via \"pip install pandas\"\n",
    "    2. pascal_voc_writer via \"pip install pascal-voc-writer\"\n",
    "    3. pillow via \"pip install pillow\"\n",
    "    \n",
    "You will require the following meta files, located in the same directory:\n",
    "    1. class_descriptions.csv\n",
    "    2. train_annotations.csv\n",
    "    3. train_images_with_rotation.csv\n",
    "    \n",
    "Subsequently, specify the source and output paths accordingly, in the variables:\n",
    "    1. imgs_source\n",
    "    2. imgs_out\n",
    "    3. meta_source\n",
    "    4. meta_out\n",
    "\n",
    "Finally, indicate the output annotation format, as either:\n",
    "    1. \"YOLO\" or \n",
    "    2. \"PASCAL VOC\"\n",
    "\n",
    "Your selected classes are stored as a list of class descriptions (case-sensitive) - add to or remove from it as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CHANGE THESE VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_source = \"/media/tingyu/WD BLUE/open_images/all/train_1\"\n",
    "imgs_out = \"/media/tingyu/WD BLUE/open_images/subset/train\"\n",
    "\n",
    "meta_source = \"/media/tingyu/WD BLUE/open_images/all\"\n",
    "meta_out = \"/media/tingyu/WD BLUE/open_images/subset\"\n",
    "\n",
    "annotation_format = \"PASCAL VOC\"\n",
    "\n",
    "classes = [\n",
    "    \"Person\",\n",
    "    # \"Man\",\n",
    "    # \"Woman\",\n",
    "    \"Human face\",\n",
    "    \"Hat\",\n",
    "    # \"Glasses\",\n",
    "    \"Sunglasses\",\n",
    "    \"Knife\",\n",
    "    \"Handgun\",\n",
    "    \"Rifle\",\n",
    "    \"Weapon\",\n",
    "    # \"Shirt\",\n",
    "    \"Jacket\",\n",
    "    \"Shorts\",\n",
    "    \"Jeans\",\n",
    "    \"Skirt\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AVOID EDITING CELLS BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pascal_voc_writer import Writer\n",
    "from PIL import Image\n",
    "from shutil import copyfile\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_descriptions = pd.read_csv(\"{}/class_descriptions.csv\".format(meta_source), header=None)\n",
    "class_descriptions.columns = [\"LabelName\", \"Description\"]\n",
    "label_names = [class_descriptions[class_descriptions[\"Description\"] == c][\"LabelName\"].values[0] \n",
    "               for c in classes]\n",
    "\"\"\"\n",
    "select LabelName, Description\n",
    "from   class_descriptions\n",
    "where  LabelName in label_names\n",
    "\"\"\"\n",
    "class_descriptions = (class_descriptions[class_descriptions[\"LabelName\"].isin(label_names)][[\"LabelName\", \"Description\"]]\n",
    "                      .sort_values([\"Description\"]))\n",
    "class_descriptions = class_descriptions.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_annotations = pd.read_csv(\"{}/train_annotations.csv\".format(meta_source))\n",
    "\"\"\"\n",
    "select *\n",
    "from   train_annotations join class_descriptions \n",
    "       on LabelName\n",
    "\"\"\"\n",
    "train_annotations = (pd.merge(train_annotations, class_descriptions, on=\"LabelName\")\n",
    "                     .sort_values([\"ImageID\"]))\n",
    "print(train_annotations.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = pd.read_csv(\"{}/train_images_with_rotation.csv\".format(meta_source))\n",
    "\"\"\"\n",
    "select *\n",
    "from   train_images join (select distinct ImageID from train_annotations) \n",
    "       on ImageID\n",
    "\"\"\"\n",
    "train_images = (pd.merge(train_images, pd.DataFrame(train_annotations[\"ImageID\"].unique(), columns=[\"ImageID\"]), on=\"ImageID\")\n",
    "                .sort_values([\"ImageID\"]))\n",
    "print(train_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_yolo_format(label_name, x_min, x_max, y_min, y_max):\n",
    "    label_idx = class_descriptions[class_descriptions[\"LabelName\"] == label_name].index[0]\n",
    "    x_mid = (x_min + x_max) / 2\n",
    "    y_mid = (y_min + y_max) / 2\n",
    "    width = x_max - x_min\n",
    "    height = y_max - y_min\n",
    "    return \"{} {} {} {} {}\".format(label_idx, x_mid, y_mid, width, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_annotations_file(folder_path, image_id):\n",
    "    annotations = train_annotations[train_annotations[\"ImageID\"] == image_id]\n",
    "    if annotation_format == \"YOLO\":\n",
    "        with open(\"{}/{}.txt\".format(folder_path, image_id), \"w+\") as file:    \n",
    "            file.write(\"\\n\".join([to_yolo_format(r[\"LabelName\"], r[\"XMin\"], r[\"XMax\"], r[\"YMin\"], r[\"YMax\"]) \n",
    "                                  for _, r in annotations.iterrows()]))\n",
    "            file.close()\n",
    "    elif annotation_format == \"PASCAL VOC\":\n",
    "        img_path = \"{}/{}.jpg\".format(folder_path, image_id)\n",
    "        img = Image.open(img_path)\n",
    "        width, height = img.size\n",
    "        writer = Writer(img_path, width, height)\n",
    "        for _, r in annotations.iterrows():\n",
    "            writer.addObject(r[\"LabelName\"], r[\"XMin\"], r[\"XMax\"], r[\"YMin\"], r[\"YMax\"])\n",
    "        writer.save(\"{}/{}.xml\".format(folder_path, image_id))\n",
    "    else:\n",
    "        raise ValueError(\"Invalid annotation format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(meta_out):\n",
    "    os.mkdir(meta_out)\n",
    "if not os.path.exists(imgs_out):\n",
    "    os.mkdir(imgs_out)\n",
    "\n",
    "with open(\"{}/subset.names\".format(meta_out), \"w+\") as names_file:\n",
    "    names_file.write(\"\\n\".join(class_descriptions[\"Description\"].tolist()))\n",
    "    names_file.close()\n",
    "\n",
    "for _, r in train_images.iterrows():\n",
    "    try:\n",
    "        image_id = r[\"ImageID\"]\n",
    "        copyfile(\"{}/{}.jpg\".format(imgs_source, image_id), \"{}/{}.jpg\".format(imgs_out, image_id))\n",
    "        create_annotations_file(imgs_out, image_id)\n",
    "    except FileNotFoundError:\n",
    "        print(\"Image {}.jpg not found, skipping\".format(image_id))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
